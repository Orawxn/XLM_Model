# XLM_Model

üß† ‡πÇ‡∏°‡πÄ‡∏î‡∏• deepset/xlm-roberta-base-squad2 
‡πÄ‡∏Ñ‡∏£‡∏∑‡πà‡∏≠‡∏á‡∏°‡∏∑‡∏≠‡∏ó‡∏µ‡πà‡πÉ‡∏ä‡πâ
- Transformers
- PEFT (LoRA)
- Accelerate
- Evaluate / Datasets
- Pandas

# ‡∏™‡∏£‡πâ‡∏≤‡∏á virtual environment
python -m venv venv
venv\Scripts\activate   # ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö Windows
# source venv/bin/activate  ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö Linux / Mac

# ‡∏ï‡∏¥‡∏î‡∏ï‡∏±‡πâ‡∏á library ‡∏ó‡∏µ‡πà‡∏à‡∏≥‡πÄ‡∏õ‡πá‡∏ô
pip install -r requirements.txt
‡∏´‡∏≤‡∏Å‡∏¢‡∏±‡∏á‡πÑ‡∏°‡πà‡∏°‡∏µ‡πÑ‡∏ü‡∏•‡πå requirements.txt
pip install torch transformers datasets peft accelerate evaluate scikit-learn pandas

# ‡∏î‡∏π‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°-‡∏Ñ‡∏≥‡∏ï‡∏≠‡∏ö ‡πÉ‡∏ô dataset
python Model/src/LoRA.py

# ‡πÇ‡∏´‡∏•‡∏î‡πÇ‡∏°‡πÄ‡∏î‡∏•
python Model/src/model.py
  
# ‡∏ó‡∏î‡∏™‡∏≠‡∏ö‡∏Å‡∏≤‡∏£‡∏ï‡∏≠‡∏ö‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏Å‡πà‡∏≠‡∏ô fine-tune
python Model/src/testmodel.py

# ‡∏´‡∏≤‡∏Ñ‡πà‡∏≤ F1 score ‡∏Ç‡∏≠‡∏á baseline
python Model/src/evaluate_Model.py
‡∏Ñ‡πà‡∏≤ F1 ‡∏Ç‡∏≠‡∏á‡πÅ‡∏ï‡πà‡∏•‡∏∞‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°‡∏≠‡∏¢‡∏π‡πÉ‡∏ô‡πÑ‡∏ü‡∏•‡πå  \archive\evaluation_results_baseline.csv

# Fine-tune ‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏î‡πâ‡∏ß‡∏¢ LoRA 
python Model/src/LoRA.py


# ‡∏ó‡∏î‡∏™‡∏≠‡∏ö‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏´‡∏•‡∏±‡∏á fine-tune 
python Model/src/test_LoRA.py

# ‡∏´‡∏≤‡∏Ñ‡πà‡∏≤ F1 score ‡∏´‡∏•‡∏±‡∏á‡∏à‡∏≤‡∏Å fine-tune ‡πÅ‡∏•‡∏∞ parameter 3 ‡∏ä‡∏∏‡∏î
python Model/src/evaluate_LoRA.py
‡∏Ñ‡πà‡∏≤ F1 ‡πÅ‡∏•‡∏∞ Em ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏•‡∏á‡πÉ‡∏ô‡πÇ‡∏ü‡∏•‡πÄ‡∏î‡∏≠‡∏£‡πå result  
\results\exp_1\evaluation_results.json
\results\exp_2\evaluation_results.json
\results\exp_3\evaluation_results.json

# test set (‡∏à‡∏≤‡∏Å‡∏û‡∏≤‡∏£‡∏≤‡∏°‡∏¥‡πÄ‡∏ï‡∏≠‡∏£‡πå‡∏ó‡∏µ‡πà‡∏î‡∏µ‡∏ó‡∏µ‡πà‡∏™‡∏∏‡∏î)
python Model/src/testset.py
‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏Ñ‡πà‡∏≤‡πÑ‡∏ß‡πâ‡∏ó‡∏µ‡πà "D:\Paper NLP\evaluation_val_test.csv"




